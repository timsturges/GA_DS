{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Project 3: Linear Regression and KNN - Train/Test Split\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "We've discussed overfitting in the context of bias and variance, and we've touched on some techniques, such as regularization, that are used to avoid overfitting (but haven't practiced them yet). In this lesson we'll discuss a fundamental method for avoiding overfitting that is commonly referred to as _train/test split_ validation. \n",
    "\n",
    "The idea is similar to something called \"cross-validation\" — in fact, it is a type of cross-validation — in that we split the data set into two subsets:\n",
    "* A subset on which to train our model.\n",
    "* A subset on which to test our model's predictions.\n",
    "\n",
    "This serves two useful purposes:\n",
    "* We prevent overfitting by not using all of the data.\n",
    "* We have some remaining data we can use to evaluate our model.\n",
    "\n",
    "While this may seem like a relatively simple idea, **there are some caveats** to putting it into practice. For example, if you are not careful, it is easy to take a non-random split. Suppose we have salary data on technical professionals that is composed of 80 percent data from California and 20 percent data from elsewhere and is sorted by state. If we split our data into 80 percent training data and 20 percent testing data, we might inadvertantly select all the California data to train and all the non-California data to test. In this case we've still overfit on our data set because we did not sufficiently randomize the data.\n",
    "\n",
    "In a situation like this we can use _k-fold cross-validation_, which is the same idea applied to more than two subsets. In particular, we partition our data into $k$ subsets and train on $k-1$ one of them, holding the last slice for testing. We can do this for each of the possible $k-1$ subsets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Independent Practice\n",
    "\n",
    "Ultimately we use a test-training split to compare multiple models on the same data set. This could be comparisons of two linear models or of completely different models on the same data.\n",
    "\n",
    "For your independent practice, fit three different models on the Boston housing data. For example, you could pick three different subsets of variables, one or more polynomial models, or any other model you'd like. \n",
    "\n",
    "### Here's What We Will Be Doing:\n",
    "\n",
    "* Working with Boston housing data to predict the value of a home\n",
    "* Create a test-train split of the data.\n",
    "* Train each of your models on the training data.\n",
    "* Evaluate each of the models on the test data.\n",
    "* Rank the models by how well they score on the testing data set.\n",
    "\n",
    "**Then, try k-folds.**\n",
    "\n",
    "* Try a few different splits of data for the same models.\n",
    "* Perform a k-fold cross-validation and use the cross-validation scores to compare your models. Did this change your rankings?\n",
    "\n",
    "**Be sure to provide interpretation for your results.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that k-fold cross-validation creates a hold portion of your data set for each iteration of training and validating:\n",
    "\n",
    "![](http://i.imgur.com/0PFrPXJ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression Use Case\n",
    "\n",
    "In this given task, you will be asked to model the median home price of various houses across U.S. Census tracts in the city of Boston. This is a probable use case: We are predicting a continuous, numeric output (price) based on a combination of discrete features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston = load_boston()\n",
    "\n",
    "X = pd.DataFrame(boston.data,\n",
    "                 columns=boston.feature_names)\n",
    "y = pd.DataFrame(boston.target,\n",
    "                 columns=['MEDV'])\n",
    "\n",
    "print(boston['DESCR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Clean Up Data and Perform Exporatory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Boston data is from scikit-learn, so it ought to be pretty clean, but we should always perform exploratory data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     15.3  396.90   4.98  \n",
       "1     17.8  396.90   9.14  \n",
       "2     17.8  392.83   4.03  \n",
       "3     18.7  394.63   2.94  \n",
       "4     18.7  396.90   5.33  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exploratory data analysis.\n",
    "\n",
    "# Include: total nulls, index, data types, shape, summary statistics, and the number of unique values for each column\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 13 columns):\n",
      "CRIM       506 non-null float64\n",
      "ZN         506 non-null float64\n",
      "INDUS      506 non-null float64\n",
      "CHAS       506 non-null float64\n",
      "NOX        506 non-null float64\n",
      "RM         506 non-null float64\n",
      "AGE        506 non-null float64\n",
      "DIS        506 non-null float64\n",
      "RAD        506 non-null float64\n",
      "TAX        506 non-null float64\n",
      "PTRATIO    506 non-null float64\n",
      "B          506 non-null float64\n",
      "LSTAT      506 non-null float64\n",
      "dtypes: float64(13)\n",
      "memory usage: 51.5 KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.613524</td>\n",
       "      <td>11.363636</td>\n",
       "      <td>11.136779</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.554695</td>\n",
       "      <td>6.284634</td>\n",
       "      <td>68.574901</td>\n",
       "      <td>3.795043</td>\n",
       "      <td>9.549407</td>\n",
       "      <td>408.237154</td>\n",
       "      <td>18.455534</td>\n",
       "      <td>356.674032</td>\n",
       "      <td>12.653063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.601545</td>\n",
       "      <td>23.322453</td>\n",
       "      <td>6.860353</td>\n",
       "      <td>0.253994</td>\n",
       "      <td>0.115878</td>\n",
       "      <td>0.702617</td>\n",
       "      <td>28.148861</td>\n",
       "      <td>2.105710</td>\n",
       "      <td>8.707259</td>\n",
       "      <td>168.537116</td>\n",
       "      <td>2.164946</td>\n",
       "      <td>91.294864</td>\n",
       "      <td>7.141062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.082045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>5.885500</td>\n",
       "      <td>45.025000</td>\n",
       "      <td>2.100175</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>375.377500</td>\n",
       "      <td>6.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.256510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.208500</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>3.207450</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.050000</td>\n",
       "      <td>391.440000</td>\n",
       "      <td>11.360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.677083</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.623500</td>\n",
       "      <td>94.075000</td>\n",
       "      <td>5.188425</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>396.225000</td>\n",
       "      <td>16.955000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>88.976200</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>37.970000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             CRIM          ZN       INDUS        CHAS         NOX          RM  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean     3.613524   11.363636   11.136779    0.069170    0.554695    6.284634   \n",
       "std      8.601545   23.322453    6.860353    0.253994    0.115878    0.702617   \n",
       "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
       "25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
       "50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
       "75%      3.677083   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
       "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
       "\n",
       "              AGE         DIS         RAD         TAX     PTRATIO           B  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean    68.574901    3.795043    9.549407  408.237154   18.455534  356.674032   \n",
       "std     28.148861    2.105710    8.707259  168.537116    2.164946   91.294864   \n",
       "min      2.900000    1.129600    1.000000  187.000000   12.600000    0.320000   \n",
       "25%     45.025000    2.100175    4.000000  279.000000   17.400000  375.377500   \n",
       "50%     77.500000    3.207450    5.000000  330.000000   19.050000  391.440000   \n",
       "75%     94.075000    5.188425   24.000000  666.000000   20.200000  396.225000   \n",
       "max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n",
       "\n",
       "            LSTAT  \n",
       "count  506.000000  \n",
       "mean    12.653063  \n",
       "std      7.141062  \n",
       "min      1.730000  \n",
       "25%      6.950000  \n",
       "50%     11.360000  \n",
       "75%     16.955000  \n",
       "max     37.970000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X.hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <td>0.910228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIS</th>\n",
       "      <th>NOX</th>\n",
       "      <td>0.769230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDUS</th>\n",
       "      <th>NOX</th>\n",
       "      <td>0.763651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <td>0.747881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOX</th>\n",
       "      <th>AGE</th>\n",
       "      <td>0.731470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAX</th>\n",
       "      <th>INDUS</th>\n",
       "      <td>0.720760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIS</th>\n",
       "      <th>INDUS</th>\n",
       "      <td>0.708027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOX</th>\n",
       "      <th>TAX</th>\n",
       "      <td>0.668023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIS</th>\n",
       "      <th>ZN</th>\n",
       "      <td>0.664408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDUS</th>\n",
       "      <th>AGE</th>\n",
       "      <td>0.644779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRIM</th>\n",
       "      <th>RAD</th>\n",
       "      <td>0.625505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RM</th>\n",
       "      <th>LSTAT</th>\n",
       "      <td>0.613808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOX</th>\n",
       "      <th>RAD</th>\n",
       "      <td>0.611441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDUS</th>\n",
       "      <th>LSTAT</th>\n",
       "      <td>0.603800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE</th>\n",
       "      <th>LSTAT</th>\n",
       "      <td>0.602339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDUS</th>\n",
       "      <th>RAD</th>\n",
       "      <td>0.595129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOX</th>\n",
       "      <th>LSTAT</th>\n",
       "      <td>0.590879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAX</th>\n",
       "      <th>CRIM</th>\n",
       "      <td>0.582764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE</th>\n",
       "      <th>ZN</th>\n",
       "      <td>0.569537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">TAX</th>\n",
       "      <th>LSTAT</th>\n",
       "      <td>0.543993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIS</th>\n",
       "      <td>0.534432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <td>0.533828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOX</th>\n",
       "      <td>0.516604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE</th>\n",
       "      <th>TAX</th>\n",
       "      <td>0.506456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIS</th>\n",
       "      <th>LSTAT</th>\n",
       "      <td>0.496996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAD</th>\n",
       "      <th>DIS</th>\n",
       "      <td>0.494588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTAT</th>\n",
       "      <th>RAD</th>\n",
       "      <td>0.488676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAD</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <td>0.464741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>TAX</th>\n",
       "      <td>0.460853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE</th>\n",
       "      <th>RAD</th>\n",
       "      <td>0.456022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RM</th>\n",
       "      <th>ZN</th>\n",
       "      <td>0.311991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAD</th>\n",
       "      <th>ZN</th>\n",
       "      <td>0.311948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <td>0.302188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAX</th>\n",
       "      <th>RM</th>\n",
       "      <td>0.292048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIS</th>\n",
       "      <th>B</th>\n",
       "      <td>0.291512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>CRIM</th>\n",
       "      <td>0.289946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">AGE</th>\n",
       "      <th>B</th>\n",
       "      <td>0.273534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTRATIO</th>\n",
       "      <td>0.261515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <td>0.240265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>DIS</th>\n",
       "      <td>0.232471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RM</th>\n",
       "      <th>CRIM</th>\n",
       "      <td>0.219247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAD</th>\n",
       "      <th>RM</th>\n",
       "      <td>0.209847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RM</th>\n",
       "      <th>DIS</th>\n",
       "      <td>0.205246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <td>0.200469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>NOX</th>\n",
       "      <td>0.188933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">B</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <td>0.177383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZN</th>\n",
       "      <td>0.175520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RM</th>\n",
       "      <th>B</th>\n",
       "      <td>0.128069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHAS</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <td>0.121515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIS</th>\n",
       "      <th>CHAS</th>\n",
       "      <td>0.099176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHAS</th>\n",
       "      <th>RM</th>\n",
       "      <td>0.091251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOX</th>\n",
       "      <th>CHAS</th>\n",
       "      <td>0.091203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE</th>\n",
       "      <th>CHAS</th>\n",
       "      <td>0.086518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">CHAS</th>\n",
       "      <th>INDUS</th>\n",
       "      <td>0.062938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRIM</th>\n",
       "      <td>0.055892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTAT</th>\n",
       "      <th>CHAS</th>\n",
       "      <td>0.053929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <th>CHAS</th>\n",
       "      <td>0.048788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZN</th>\n",
       "      <th>CHAS</th>\n",
       "      <td>0.042697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAX</th>\n",
       "      <th>CHAS</th>\n",
       "      <td>0.035587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHAS</th>\n",
       "      <th>RAD</th>\n",
       "      <td>0.007368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     corr\n",
       "RAD     TAX      0.910228\n",
       "DIS     NOX      0.769230\n",
       "INDUS   NOX      0.763651\n",
       "AGE     DIS      0.747881\n",
       "NOX     AGE      0.731470\n",
       "TAX     INDUS    0.720760\n",
       "DIS     INDUS    0.708027\n",
       "NOX     TAX      0.668023\n",
       "DIS     ZN       0.664408\n",
       "INDUS   AGE      0.644779\n",
       "CRIM    RAD      0.625505\n",
       "RM      LSTAT    0.613808\n",
       "NOX     RAD      0.611441\n",
       "INDUS   LSTAT    0.603800\n",
       "AGE     LSTAT    0.602339\n",
       "INDUS   RAD      0.595129\n",
       "NOX     LSTAT    0.590879\n",
       "TAX     CRIM     0.582764\n",
       "AGE     ZN       0.569537\n",
       "TAX     LSTAT    0.543993\n",
       "        DIS      0.534432\n",
       "ZN      INDUS    0.533828\n",
       "        NOX      0.516604\n",
       "AGE     TAX      0.506456\n",
       "DIS     LSTAT    0.496996\n",
       "RAD     DIS      0.494588\n",
       "LSTAT   RAD      0.488676\n",
       "RAD     PTRATIO  0.464741\n",
       "PTRATIO TAX      0.460853\n",
       "AGE     RAD      0.456022\n",
       "...                   ...\n",
       "RM      ZN       0.311991\n",
       "RAD     ZN       0.311948\n",
       "NOX     RM       0.302188\n",
       "TAX     RM       0.292048\n",
       "DIS     B        0.291512\n",
       "PTRATIO CRIM     0.289946\n",
       "AGE     B        0.273534\n",
       "        PTRATIO  0.261515\n",
       "RM      AGE      0.240265\n",
       "PTRATIO DIS      0.232471\n",
       "RM      CRIM     0.219247\n",
       "RAD     RM       0.209847\n",
       "RM      DIS      0.205246\n",
       "CRIM    ZN       0.200469\n",
       "PTRATIO NOX      0.188933\n",
       "B       PTRATIO  0.177383\n",
       "        ZN       0.175520\n",
       "RM      B        0.128069\n",
       "CHAS    PTRATIO  0.121515\n",
       "DIS     CHAS     0.099176\n",
       "CHAS    RM       0.091251\n",
       "NOX     CHAS     0.091203\n",
       "AGE     CHAS     0.086518\n",
       "CHAS    INDUS    0.062938\n",
       "        CRIM     0.055892\n",
       "LSTAT   CHAS     0.053929\n",
       "B       CHAS     0.048788\n",
       "ZN      CHAS     0.042697\n",
       "TAX     CHAS     0.035587\n",
       "CHAS    RAD      0.007368\n",
       "\n",
       "[78 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = pd.DataFrame(X.corr().abs().unstack().sort_values(ascending = False))\n",
    "c.columns = ['corr']\n",
    "c[c['corr'] < 1].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>22.532806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.197104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>17.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>21.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             MEDV\n",
       "count  506.000000\n",
       "mean    22.532806\n",
       "std      9.197104\n",
       "min      5.000000\n",
       "25%     17.025000\n",
       "50%     21.200000\n",
       "75%     25.000000\n",
       "max     50.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# y.hist();\n",
    "np.log1p(y).hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of EDA:\n",
    "\n",
    "1. There are no non-null values in our data, and therefore no values to impute.\n",
    "2. RAD and TAX features are very highly correlated (abs > 0.9), suggesting a strong relationship between the two features. Therefore, at least one of these variables should not be included, as they are more likely to dampen the other's predictive power.\n",
    "3. There is significant clustering and high variance in the data, and since Linear Regression and KNN models make assumptions about the shape of the data, the features will be standardized as part of our pre-processing. Additionally, the y values will be log+1 transformed to improve the predictions, a transformation which will require the inverse transformation after predictions are generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization of features\n",
    "X = (X - X.mean()) / X.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log+1 transformation of target\n",
    "y = np.log1p(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `scikit-learn` Linear Regression\n",
    "\n",
    "### 2. Pick 3-4 predictors (i.e. CRIM, ZN, etc...) that you will use to predict our target variable, MEDV.\n",
    "Score and plot your predictions. What do these results tell us?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y['MEDV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['CHAS','RAD','TAX','ZN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38096533662889087"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X[cols],y)\n",
    "lr.score(X[cols],y)\n",
    "# lr.fit(X,y)\n",
    "# lr.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vars</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZN</td>\n",
       "      <td>0.086792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RAD</td>\n",
       "      <td>0.072758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHAS</td>\n",
       "      <td>0.056929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TAX</td>\n",
       "      <td>-0.253147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Vars    Weight\n",
       "3    ZN  0.086792\n",
       "1   RAD  0.072758\n",
       "0  CHAS  0.056929\n",
       "2   TAX -0.253147"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs = pd.DataFrame({\n",
    "    'Vars': X[cols].columns,\n",
    "    'Weight': lr.coef_\n",
    "}).sort_values(by='Weight', ascending=False)\n",
    "\n",
    "coeffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    "ZN, RAD, and CHAS are all comparably strong predictors, while TAX is less so. Overall, the R-squared score of 0.38 is significantly worse than when using all of the features, suggesting that too much is lost by these variable choices. In this case I would probably consider a subtractive feature selection process over an additive one, at least for the Linear Regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Try 70/30 and 90/10 train/test splits (70% of the data for training - 30% for testing, then 90% for training - 10% for testing)\n",
    "Score and plot. How do your metrics change? What does this tell us about the size of training/testing splits?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X[cols], \n",
    "                                                    y, \n",
    "                                                    test_size = 0.3, \n",
    "                                                    random_state=2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.3856403518140561, Test Score: 0.35053922216379774\n"
     ]
    }
   ],
   "source": [
    "lr.fit(X_train, y_train)\n",
    "print(\"Train Score: {}, Test Score: {}\".format(lr.score(X_train, y_train), lr.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X[cols], \n",
    "                                                    y, \n",
    "                                                    test_size = 0.1, \n",
    "                                                    random_state=2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.373166944132569, Test Score: 0.437820100183711\n"
     ]
    }
   ],
   "source": [
    "lr.fit(X_train, y_train)\n",
    "print(\"Train Score: {}, Test Score: {}\".format(lr.score(X_train, y_train), lr.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    "\n",
    "Due to relatively low R-scores, the different in the 70/30 vs 90/10 train/test splitting is not very pronounced, at least in the training data. What is significant is the dramatic difference between the training and testing scores in the 90/10 split data. One might at first be pleasantly surprised by seeing such a large improvement between the training and testing scores, but in practice it would be more helpful to be able to deploy a model with more predictable results. Such a model may have a high amount of variance when applied to new data, and is therefore difficult to anticipate its actual performance when deployed in production."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Use k-fold cross validation varying the number of folds from 5 to 10\n",
    "What seems optimal? How do your scores change? What is the variance like? Try different folds to get a sense of how this impacts your score. What are the tradeoffs associated with choosing the number of folds?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing to 80/20 train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[cols], \n",
    "                                                    y, \n",
    "                                                    test_size = 0.2, \n",
    "                                                    random_state=2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_5 = cross_val_score(estimator = lr,\n",
    "                           X=X_train, \n",
    "                           y=y_train,\n",
    "                           cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Score 5-fold CV:  0.33507737912173147 \n",
      " Score STD 5-fold CV:  0.1101337482275364\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean Score 5-fold CV: \",\n",
    "      np.mean(scores_5),\n",
    "      \"\\n\",\n",
    "      \"Score STD 5-fold CV: \",\n",
    "      np.std(scores_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_10 = cross_val_score(estimator = lr,\n",
    "                            X=X_train, \n",
    "                            y=y_train,\n",
    "                            cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Score 10-fold CV:  0.34105753090399193 \n",
      " Score STD 10-fold CV:  0.10870223702906306\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean Score 10-fold CV: \",\n",
    "      np.mean(scores_10),\n",
    "      \"\\n\",\n",
    "      \"Score STD 10-fold CV: \",\n",
    "      np.std(scores_10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    "The higher numer of folds in cross-validation is modest, however in addition to the slight improvement in mean score, the scores also vary less, suggesting slightly improved confidence in the model's predictive capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice:\n",
    "\n",
    "Unsatisfied with these results, I'm going to attempt some other models and use all of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr = Ridge()\n",
    "lsr = Lasso()\n",
    "\n",
    "# 80/20 train/test split, using all features except for RAD due to high correlation with TAX\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size = 0.2, \n",
    "                                                    random_state=2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simultaneously attempting Lasso and Ridge, tuning the alpha parameters for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.logspace(-4, 4, 9)\n",
    "lsr_scores = []\n",
    "rr_scores = []\n",
    "\n",
    "for a in alphas:\n",
    "    lsr.set_params(alpha = a)\n",
    "    rr.set_params(alpha = a)\n",
    "    scores = cross_val_score(estimator = lsr, X=X_train, y = y_train, cv = 10)\n",
    "    lsr_scores.append((np.mean(scores), a))\n",
    "    scores = cross_val_score(estimator = rr, X=X_train, y = y_train, cv = 10)\n",
    "    rr_scores.append((np.mean(scores), a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7814572182231376, 0.001)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(lsr_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7820647667994132, 10.0)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(rr_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6836848455945553"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsr.set_params(alpha = 0.001)\n",
    "lsr.fit(X_train, y_train)\n",
    "lsr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6825821601357425"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rr.set_params(alpha = 10)\n",
    "rr.fit(X_train, y_train)\n",
    "rr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Random Forests With the Boston Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create X and y variables for Your Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reloading the data; we know that Random Forests do not make the assumptions about the data shape, so standardization\n",
    "# will be skipped, although the target will still be logp1 transformed\n",
    "X = pd.DataFrame(boston.data,\n",
    "                 columns=boston.feature_names)\n",
    "y = pd.DataFrame(boston.target,\n",
    "                 columns=['MEDV'])\n",
    "y = np.log1p(y)\n",
    "y = y['MEDV']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Divide it into a training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80/20 train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size = 0.2, \n",
    "                                                    random_state=2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit a Random Forest on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestRegressor()\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What are its most important features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LSTAT</th>\n",
       "      <td>0.576807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RM</th>\n",
       "      <td>0.203049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRIM</th>\n",
       "      <td>0.082906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIS</th>\n",
       "      <td>0.050465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOX</th>\n",
       "      <td>0.029763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAX</th>\n",
       "      <td>0.013119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>0.011939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE</th>\n",
       "      <td>0.011817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTRATIO</th>\n",
       "      <td>0.010032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDUS</th>\n",
       "      <td>0.005907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAD</th>\n",
       "      <td>0.002647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZN</th>\n",
       "      <td>0.000931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHAS</th>\n",
       "      <td>0.000618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         importance\n",
       "LSTAT      0.576807\n",
       "RM         0.203049\n",
       "CRIM       0.082906\n",
       "DIS        0.050465\n",
       "NOX        0.029763\n",
       "TAX        0.013119\n",
       "B          0.011939\n",
       "AGE        0.011817\n",
       "PTRATIO    0.010032\n",
       "INDUS      0.005907\n",
       "RAD        0.002647\n",
       "ZN         0.000931\n",
       "CHAS       0.000618"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = pd.DataFrame(rf.feature_importances_,\n",
    "                                   index = X_train.columns,\n",
    "                                    columns=['importance']).sort_values('importance',ascending=False)\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    "In the Random Forest Classifier model, the LSTAT, RM, and CRIM features are the 3 most signifcant features in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How well does your model perform on your test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.787232157422018"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    "The Random Forest Regressor model performs significantly better than the first Linear Regression model, however it is worth noting that the Linear Regression model above was limited to 4 features. Later, using more features models, we performed better, but still not as good as the Random Forest Regressor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge:  Try and find at least two improvements to your model to improve test scores.\n",
    "\n",
    "You can try the following:\n",
    " - increasing the number of trees\n",
    " - using a different number of maximum features to sample\n",
    " - using a different number of minimum samples per leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Trees:  1\n",
      "# Trees:  10\n",
      "# Trees:  25\n",
      "# Trees:  50\n",
      "# Trees:  100\n",
      "# Trees:  1000\n"
     ]
    }
   ],
   "source": [
    "# to conveniently optimize the random forest model, use three nested loops to tune 3 model parameters\n",
    "rf_scores = []\n",
    "\n",
    "n_tr = [1, 10, 25, 50, 100, 1000]\n",
    "spl = [1, 2, 4, 8, 16, 32]\n",
    "mx_ft = [1, 0.5, 'sqrt', 'log2', len(X_train.columns) - 1]\n",
    "\n",
    "for t in n_tr:\n",
    "    print(\"# Trees: \", t)\n",
    "    for m in mx_ft:\n",
    "        for s in spl:\n",
    "            rf.set_params(n_estimators = t,\n",
    "                          max_features = m, \n",
    "                          min_samples_leaf = s,\n",
    "                          n_jobs = -1)\n",
    "            scores = cross_val_score(estimator = rf, X = X_train, y = y_train, cv = 10)\n",
    "            rf_scores.append((np.mean(scores), t, m, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8714913193306769, 1000, 0.5, 1)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(rf_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8314223994333537"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train, y_train)\n",
    "rf.set_params(n_estimators = 1000,\n",
    "              max_features = 0.5, \n",
    "              min_samples_leaf = 1)\n",
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    "Some mild hyperparameter tuning suggests that the optimum paramters for the random forest are:\n",
    "1. n_estimators (# trees) = 1000\n",
    "2. max_features = 50% of features\n",
    "3. min_samples_leaf = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Using the Statsmodels Formula\n",
    "\n",
    "Adapt the formula example using your metrics. We will review this implementation in class. Here is a reference to consider. The workflow is the same, but the syntax is a little different. We want to get accustomed to the formula syntax because we will be using them a lot more with regressions. The results should be comparable to scikit-learn's regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, format our data in a DataFrame\n",
    "\n",
    "df = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "df['MEDV'] = boston.target\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up our new statsmodel.formula handling model\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# You can easily swap these out to test multiple versions/different formulas\n",
    "formulas = {\n",
    "    \"case1\": \"MEDV ~ RM + LSTAT + RAD + TAX + NOX + INDUS + CRIM + ZN - 1\", # - 1 = remove intercept\n",
    "    \"case2\": \"MEDV ~ NOX + RM\",\n",
    "    \"case3\": \"MEDV ~ RAD + TAX\"\n",
    "}\n",
    "\n",
    "model = smf.ols(formula=formulas['case1'], data=df)\n",
    "result = model.fit()\n",
    "\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus Challenge #1:\n",
    "\n",
    "Can you optimize your R2, selecting the best features and using either test-train split or k-folds?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus Challenge #2:\n",
    "\n",
    "Given a combination of predictors, can you find another response variable that can be accurately predicted through the exploration of different predictors in this data set?\n",
    "\n",
    "_Tip: Check out pairplots, coefficients, and Pearson scores._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out variable relations\n",
    "import seaborn as sns\n",
    "\n",
    "sns.pairplot(X);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out Pearson scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo: Patsy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import patsy\n",
    "\n",
    "# Add response to the core DataFrame\n",
    "df['MEDV'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split #If you didn't import it earlier, do so now\n",
    "\n",
    "# Easily change your variable predictors without reslicing your DataFrame\n",
    "y, X = patsy.dmatrices(\"MEDV ~ AGE + RM\", data=df, return_type=\"dataframe\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Rerun your model, iteratively changing your variables and train_size from the previous cell\n",
    "\n",
    "lm = LinearRegression()\n",
    "model = lm.fit(X_train, y_train)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "print(\"R^2 Score: {}\".format(metrics.r2_score(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
