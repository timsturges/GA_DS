{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework 3:  Master Regression on the Ames Housing Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This homework is meant to be a more open ended, exploratory way for students to complete their assignment for Homework project #3. \n",
    "\n",
    "Instead of doing the pre-assigned tasks in the other projects given, you can use this homework as a chance to develop your own model using the Ames Housing dataset, as discussed here:  https://www.kaggle.com/c/house-prices-advanced-regression-techniques/overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your homework assignment will be to try and get the best leaderboard score that you can, using techniques learned so far in class, in addition to whatever else you find online.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class will be a continuation of what was covered in class 14 when we made our first submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In so doing, present the following 5 questions to class when you are finished."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What was your final leaderboard score?  How many submissions did it take for you to get there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### First improvement attempt\n",
    "# jumped 715 positions (2483 from 3198)\n",
    "# Your submission scored 0.14225, which is an improvement of your previous score of 0.16798 (baseline)\n",
    "# This was a fairly dirty attempt to clean the dataset. I was not careful with my feature handling, and undoubtedly \n",
    "# used a lot of unnecessary features which were not very instructive. Further, it was not very programmatic.\n",
    "# Essentially I looked at each column one-by-one and considered what to do with it.\n",
    "\n",
    "# In my second attempt, I looked at several kaggle kernels to get some ideas. The first thing I noticed was that \n",
    "# good notebooks were using user-defined functions to do their cleaning. Initially I thought I would build \n",
    "# functions for each column, but determined that was still not a good choice, so I wrote functions to handle\n",
    "# edge cases and clean numeric or categorical variables.\n",
    "\n",
    "# Final score was a 0.14192, which is an improvement of your previous score of 0.14225. I jumped 12 more spots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What types of techniques did you use?  Which ones worked best, which ones didn't?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Although I had already implemented nested loops for tuning parameters, after learning about GridSearchCV, I\n",
    "# I simplified the code significantly. It seems that I didn't go far enough with the simplification of my categorical\n",
    "# variables, and ought to have considered limiting MANY more features, and then looking at those limited features\n",
    "# more closely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What new features or modifications did you make to your data that helped your score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I didn't create new features, but I was sure to fill NaNs in a resonable way, and cut categorical variables\n",
    "# with fewer than 30 values into a single category to simplifiy them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How reliable was the association between your validation and test scores?  What steps did you take to correct this measure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Even after the first attempt, the proximity between validation and test scores improved significantly. With \n",
    "# my various trials, I was sure to think through my cleaning as much as possible before starting the GridSearch, \n",
    "# due to the significant downtime while tuning / fitting the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What surprised you the most when it came to your results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The diminishing returns with regard to the extra effort vs the improvement made. Even though I knew there were \n",
    "# certain ways that I could do things better with more time, I expected a much better improvement between my second\n",
    "# and third efforts, rather than a negligible one.\n",
    "\n",
    "# I was also surprised how few features had really significant importance in the model. Only 15 features (out of 180)\n",
    "# were more than 1% significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If you could, what would you like to explore in the future with regards to this sort of problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm certain that I could further improve the results by being more careful about how I encoded the categorical\n",
    "# variables. For one, the ordinal variables certainly need to be ordered, rather than somewhat random.\n",
    "# Secondly, doing this for every dataset should be written in such a way so that formulas can do this intelligently.\n",
    "# Write formulas for smartly handling numeric transformations, non-ordinal categorical variables, and categorical\n",
    "# variables. Take a closer look at the variables "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
